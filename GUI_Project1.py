import streamlit as st 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image

import re
import unicodedata
import datetime as dt
import io

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor, IsolationForest
from sklearn import metrics

# =========================
# 0. C·∫§U H√åNH FILE L∆ØU B·∫§T TH∆Ø·ªúNG M·ªöI
# =========================
ANOMALY_NEW_FILE = "anomalies_new.xlsx"


def load_new_anomalies():
    """
    Load file Excel l∆∞u c√°c tin ƒëƒÉng b·∫•t th∆∞·ªùng m·ªõi.
    N·∫øu ch∆∞a c√≥ file th√¨ tr·∫£ v·ªÅ DataFrame r·ªóng.
    """
    try:
        df_new = pd.read_excel(ANOMALY_NEW_FILE)
        if 'thoi_gian_dang' in df_new.columns:
            df_new['thoi_gian_dang'] = pd.to_datetime(df_new['thoi_gian_dang'],
                                                      errors='coerce')
        return df_new
    except Exception:
        return pd.DataFrame()


def append_new_anomaly(record: dict):
    """
    Th√™m 1 b·∫£n ghi b·∫•t th∆∞·ªùng m·ªõi v√†o file Excel.
    """
    df_existing = load_new_anomalies()
    df_new_row = pd.DataFrame([record])
    df_all = pd.concat([df_existing, df_new_row], ignore_index=True)
    df_all.to_excel(ANOMALY_NEW_FILE, index=False)


# =========================
# 1. C·∫§U H√åNH CHUNG
# =========================
st.set_page_config(
    page_title="D·ª± ƒëo√°n gi√° xe m√°y c≈© v√† ph√°t hi·ªán b·∫•t th∆∞·ªùng",
    layout="centered"
)

# ==== CSS ====
st.markdown(
    """
    <style>
    /* N·ªÅn t·ªïng th·ªÉ */
    .stApp {
        background: linear-gradient(135deg, #fdfbff 0%, #f5f7ff 50%, #fff7f5 100%);
    }

    /* Kh·ªëi n·ªôi dung trung t√¢m */
    .block-container {
        padding-top: 1.5rem;
        padding-bottom: 1.5rem;
    }

    /* Sidebar*/
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #fef6ff 0%, #e0f2fe 50%, #fdf2f8 100%);
    }

    [data-testid="stSidebar"] * {
        font-size: 0.95rem;
    }

    /* Ti√™u ƒë·ªÅ menu sidebar */
    [data-testid="stSidebar"] h2, [data-testid="stSidebar"] h3 {
        color: #374151;
        font-weight: 700;
    }

    /* Radio button trong sidebar */
    [data-testid="stSidebar"] [data-baseweb="radio"] label {
        background-color: rgba(255, 255, 255, 0.7);
        border-radius: 999px;
        padding: 4px 10px;
        margin-bottom: 4px;
    }

    /* N√∫t b·∫•m*/
    .stButton>button {
        background: linear-gradient(90deg, #a5b4fc, #f9a8d4);
        color: #1f2933;
        border-radius: 999px;
        padding: 0.5rem 1.6rem;
        border: none;
        font-weight: 600;
        font-size: 0.95rem;
        box-shadow: 0 4px 10px rgba(148, 163, 233, 0.4);
        transition: all 0.15s ease-in-out;
    }

    .stButton>button:hover {
        box-shadow: 0 6px 14px rgba(244, 114, 182, 0.5);
        transform: translateY(-1px);
        filter: brightness(1.03);
    }

    .stButton>button:active {
        transform: translateY(0px) scale(0.99);
        box-shadow: 0 2px 6px rgba(148, 163, 233, 0.4);
    }

    /* Dataframe card */
    .dataframe tbody tr:nth-child(even) {
        background-color: #f9fafb;
    }

    /* Nh·ªè l·∫°i font b·∫£ng m·ªôt ch√∫t cho g·ªçn */
    .stDataFrame, .stDataFrame table {
        font-size: 0.9rem;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# Banner
try:
    img = Image.open("Banner.PNG")
    img = img.resize((img.width, 350))
    st.image(img, use_container_width=True)
except Exception as e:
    st.warning(f"Kh√¥ng th·ªÉ load Banner.png: {e}")

# ===== TI√äU ƒê·ªÄ CH√çNH: t√¥ m√†u + canh gi·ªØa =====
st.markdown(
    """
    <div style="
        background: linear-gradient(120deg, #e0f2fe 0%, #f5d0fe 50%, #fee2e2 100%);
        padding: 18px 25px;
        border-radius: 16px;
        text-align: center;
        margin-bottom: 20px;
        box-shadow: 0 6px 18px rgba(148, 163, 233, 0.4);
    ">
        <h1 style="color:#111827; margin:0; font-size: 1.9rem; text-align:center;">
            D·ª± ƒëo√°n gi√° xe m√°y c≈© v√† ph√°t hi·ªán b·∫•t th∆∞·ªùng
        </h1>
    </div>
    """,
    unsafe_allow_html=True
)

# H√†m t·∫°o header
def pastel_header(icon: str, text: str, color: str = "#e0f2fe"):
    st.markdown(
        f"""
        <div style="
            background-color:{color};
            border-radius: 12px;
            padding: 10px 14px;
            margin: 18px 0 10px 0;
            border: 1px solid rgba(148, 163, 233, 0.5);
        ">
            <h3 style="margin:0; color:#111827; font-weight:650; font-size:1.1rem;">
                {icon} {text}
            </h3>
        </div>
        """,
        unsafe_allow_html=True
    )

# =========================
# 2. H√ÄM TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU
# =========================
def preprocessing_data(df, is_train=True):
    df = df.copy()
    # l√†m s·∫°ch t√™n c·ªôt: b·ªè d·∫•u, k√Ω t·ª± ƒë·∫∑c bi·ªát -> d·∫°ng snake_case
    d = {ord('ƒë'): 'd', ord('ƒê'): 'D'}

    def clean_col(name: str) -> str:
        s = unicodedata.normalize('NFKD', str(name)).translate(d)
        s = ''.join(ch for ch in s if not unicodedata.combining(ch))
        return re.sub(r'\W+', '_', s.lower()).strip('_')

    df.columns = [clean_col(c) for c in df.columns]

    # X√≥a tr√πng href n·∫øu c√≥
    if 'href' in df.columns:
        df = df.drop_duplicates(subset='href', keep='first')

    # Chu·∫©n h√≥a c·ªôt gi√° n·∫øu c√≥
    if 'gia' in df.columns:
        def clean_price(value):
            if pd.isna(value):
                return np.nan
            text = str(value).lower().strip()
            text = text.replace(',', '.').replace(' ', '')
            # N·∫øu c√≥ 'ƒë' ho·∫∑c 'vnd', chia 1_000_000
            if 'ƒë' in text or 'vnd' in text:
                num = re.sub(r'[^0-9]', '', text)
                return float(num) / 1_000_000 if num else np.nan
            try:
                return float(text)
            except Exception:
                return np.nan

        df['gia'] = df['gia'].apply(clean_price)

    # Chu·∫©n h√≥a kho·∫£ng gi√° n·∫øu c√≥
    for col in ['khoang_gia_min', 'khoang_gia_max']:
        if col in df.columns:
            def clean_price_2(value):
                if pd.isna(value):
                    return np.nan
                text = str(value).lower().strip()
                text = text.replace(',', '.').replace(' ', '')
                num = re.sub(r'[^0-9\.]', '', text)
                if num == '':
                    return np.nan
                try:
                    return float(num)
                except Exception:
                    return np.nan
            df[col] = df[col].apply(clean_price_2)

    # T·∫°o feature tuoi_xe
    if 'nam_dang_ky' in df.columns:
        df['nam_dang_ky'] = df['nam_dang_ky'].replace('tr∆∞·ªõc nƒÉm 1980', '1979')
        current_year = dt.date.today().year
        df['tuoi_xe'] = (current_year - pd.to_numeric(df['nam_dang_ky'], errors='coerce')).clip(lower=0)

    # Chuy·ªÉn ki·ªÉu d·ªØ li·ªáu
    if 'so_km_da_di' in df.columns:
        df['so_km_da_di'] = pd.to_numeric(df['so_km_da_di'], errors='coerce')

    # Drop c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt
    drop_cols = [
        'id', 'tieu_de', 'dia_chi', 'mo_ta_chi_tiet',
        'href', 'trong_luong', 'chinh_sach_bao_hanh',
        'tinh_trang', 'nam_dang_ky'
    ]
    df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')

    # X·ª≠ l√Ω missing values s∆° b·ªô
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if 'gia' in num_cols:
        num_cols.remove('gia')
    cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()

    for col in num_cols:
        median_val = df[col].median()
        df[col] = df[col].fillna(median_val)

    for col in cat_cols:
        mode_val = df[col].mode()
        fill_val = mode_val[0] if not mode_val.empty else "Unknown"
        df[col] = df[col].fillna(fill_val)

    # N·∫øu l√† train v√† c√≥ c·ªôt gi√° th√¨ drop NA
    if is_train and 'gia' in df.columns:
        df = df.dropna(subset=['gia']).reset_index(drop=True)

    # Chu·∫©n h√≥a 1 s·ªë category
    if 'dung_tich_xe' in df.columns:
        df['dung_tich_xe'] = df['dung_tich_xe'].replace({
            'Kh√¥ng bi·∫øt r√µ': 'Khac',
            'ƒêang c·∫≠p nh·∫≠t': 'Khac',
            'Nh·∫≠t B·∫£n': 'Khac'
        })
    if 'xuat_xu' in df.columns:
        df['xuat_xu'] = df['xuat_xu'].replace('B·∫£o h√†nh h√£ng', 'Dang cap nhat')

    if 'thuong_hieu' in df.columns and is_train:
        threshold = 10
        popular = df['thuong_hieu'].value_counts()
        popular = popular[popular >= threshold].index
        df['thuong_hieu'] = df['thuong_hieu'].apply(
            lambda x: x if x in popular else 'Hang khac'
        )

    if 'dong_xe' in df.columns and is_train:
        threshold = 10
        popular = df['dong_xe'].value_counts()
        popular = popular[popular >= threshold].index
        df['dong_xe'] = df['dong_xe'].apply(
            lambda x: x if x in popular else 'Khac'
        )

    # Ph√¢n kh√∫c theo th∆∞∆°ng hi·ªáu + lo·∫°i b·ªè outlier theo ph√¢n kh√∫c
    if 'gia' in df.columns and 'thuong_hieu' in df.columns and is_train:
        if df.empty or df['thuong_hieu'].nunique() == 0:
            df['phan_khuc'] = np.nan
        else:
            brand_mean = df.groupby('thuong_hieu', as_index=False)['gia'].mean().rename(
                columns={'gia': 'mean_price'}
            )
            if brand_mean.empty:
                df['phan_khuc'] = np.nan
            else:
                brand_mean['phan_khuc'] = pd.cut(
                    brand_mean['mean_price'],
                    bins=[-float('inf'), 50, 100, float('inf')],
                    labels=['pho_thong', 'trung_cap', 'cao_cap'],
                    right=False
                )
                df = df.merge(
                    brand_mean[['thuong_hieu', 'phan_khuc']],
                    on='thuong_hieu',
                    how='left'
                )
                df['phan_khuc'] = df['phan_khuc'].astype('object')

        # Lo·∫°i outlier theo IQR trong t·ª´ng ph√¢n kh√∫c
        def remove_outliers_by_brand(df_local, column,
                                     lower_percentile=0.25,
                                     upper_percentile=0.75,
                                     threshold=1.5):
            if column not in df_local.columns:
                return df_local

            def remove_group_outliers(group):
                Q1 = group[column].quantile(lower_percentile)
                Q3 = group[column].quantile(upper_percentile)
                IQR = Q3 - Q1
                lower_bound = Q1 - threshold * IQR
                upper_bound = Q3 + threshold * IQR
                return group[(group[column] >= lower_bound) &
                             (group[column] <= upper_bound)]

            return df_local.groupby('phan_khuc', group_keys=False).apply(
                remove_group_outliers
            )

        remove_outlier_cols = [
            c for c in ['gia', 'so_km_da_di', 'tuoi_xe'] if c in df.columns
        ]
        for c in remove_outlier_cols:
            df = remove_outliers_by_brand(df, c)
        df = df.reset_index(drop=True)

    # SAU KHI LO·∫†I OUTLIER: xo√° c·ªôt phan_khuc, KH√îNG ƒë∆∞a v√†o m√¥ h√¨nh ML
    df = df.drop(columns=['phan_khuc'], errors='ignore')

    return df

# =========================
# 3. H√ÄM PH√ÅT HI·ªÜN B·∫§T TH∆Ø·ªúNG
# =========================
def detect_anomalies(df, model, threshold=50, method='absolute'):
    """
    method:
        - 'absolute': d√πng ng∆∞·ª°ng score tuy·ªát ƒë·ªëi (>= threshold)
        - 'percentile': d√πng ph√¢n v·ªã score (threshold = 0‚Äì100, v√≠ d·ª• 95 -> top 5%)
    """
    df = df.copy()

    # D·ª± ƒëo√°n gi√° t·ª´ m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
    exclude_cols = ['gia', 'is_new']
    feature_cols = [c for c in df.columns if c not in exclude_cols]
    df['gia_predict'] = model.predict(df[feature_cols])

    # T√≠nh residual v√† z-score
    df['resid'] = df['gia'] - df['gia_predict']

    def compute_resid_z(df_local):
        if 'thuong_hieu' not in df_local.columns:
            global_mean = df_local['resid'].mean()
            global_std = df_local['resid'].std(ddof=0)
            if global_std > 0:
                df_local['resid_z'] = (df_local['resid'] - global_mean) / global_std
            else:
                df_local['resid_z'] = 0.0
            return df_local

        group_sizes = df_local['thuong_hieu'].value_counts()
        small_groups = group_sizes[group_sizes < 2].index

        df_local['resid_z'] = 0.0

        big_brands = group_sizes[group_sizes >= 2].index
        df_local.loc[df_local['thuong_hieu'].isin(big_brands), 'resid_z'] = \
            df_local.groupby('thuong_hieu')['resid'].transform(
                lambda x: (x - x.mean()) / x.std(ddof=0)
                if x.std(ddof=0) > 0 else 0
            )

        global_mean = df_local['resid'].mean()
        global_std = df_local['resid'].std(ddof=0)
        if global_std > 0:
            mask = df_local['thuong_hieu'].isin(small_groups)
            df_local.loc[mask, 'resid_z'] = (
                df_local.loc[mask, 'resid'] - global_mean
            ) / global_std
        return df_local

    df = compute_resid_z(df)

    # Kho·∫£ng tin c·∫≠y d·ª±a tr√™n ph√¢n v·ªã 10‚Äì90 c·ªßa gi√°
    p10, p90 = np.percentile(df['gia'].dropna(), [10, 90])

    # ƒê·∫£m b·∫£o numeric
    for col in ['gia', 'khoang_gia_min', 'khoang_gia_max']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')

    # Vi ph·∫°m min/max n·∫øu c√≥ kho·∫£ng gi√°
    if {'khoang_gia_min', 'khoang_gia_max'}.issubset(df.columns):
        df['vi_pham_minmax'] = (
            (df['gia'] < df['khoang_gia_min']) |
            (df['gia'] > df['khoang_gia_max'])
        ).astype(int)
    else:
        df['vi_pham_minmax'] = 0

    # Ngo√†i kho·∫£ng tin c·∫≠y
    df['ngoai_khoang_tin_cay'] = (
        (df['gia'] < p10) | (df['gia'] > p90)
    ).astype(int)

    # Isolation Forest tr√™n m·ªôt s·ªë feature numeric
    iso_features = [
        'gia', 'gia_predict', 'resid', 'resid_z',
        'so_km_da_di', 'tuoi_xe'
    ]
    iso_features = [c for c in iso_features if c in df.columns]

    if len(iso_features) > 0:
        iso = IsolationForest(contamination=0.05, random_state=42)
        df['iso_score'] = iso.fit_predict(df[iso_features])
        df['iso_score'] = df['iso_score'].apply(lambda x: 1 if x == -1 else 0)
    else:
        df['iso_score'] = 0

    # T√≠nh ƒëi·ªÉm t·ªïng h·ª£p (0‚Äì100)
    w1, w2, w3, w4 = 0.4, 0.2, 0.2, 0.2
    df['score'] = 100 * (
        (w1 * np.abs(df['resid_z']) +
         w2 * df['vi_pham_minmax'] +
         w3 * df['ngoai_khoang_tin_cay'] +
         w4 * df['iso_score'])
        / (w1 + w2 + w3 + w4)
    )

    # √Åp d·ª•ng ng∆∞·ª°ng
    if method == 'percentile':
        perc = float(np.clip(threshold, 0, 100))
        threshold_value = np.percentile(df['score'], perc)
        df['is_anomaly'] = (df['score'] > threshold_value).astype(int)
    else:
        threshold_value = threshold
        df['is_anomaly'] = (df['score'] >= threshold_value).astype(int)

    df_result = df.sort_values('score', ascending=False).reset_index(drop=True)
    return df_result, threshold_value

# =========================
# 4. LOAD DATA & TRAIN MODEL (M·∫∂C ƒê·ªäNH)
# =========================
@st.cache_data
def load_data(path="data_motobikes.xlsx"):
    df_raw = pd.read_excel(path)
    df_processed = preprocessing_data(df_raw, is_train=True)
    return df_raw, df_processed


@st.cache_resource
def train_rf_model(df_processed, n_estimators=200,
                   max_depth=None, random_state=42):
    df = df_processed.copy()
    if 'gia' not in df.columns:
        raise ValueError("Kh√¥ng t√¨m th·∫•y c·ªôt 'gia' trong d·ªØ li·ªáu sau ti·ªÅn x·ª≠ l√Ω")

    y = df['gia']
    X = df.drop(columns=['gia'])

    # T√°ch train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=random_state
    )

    # X√°c ƒë·ªãnh numeric / categorical
    numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()
    categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()

    numeric_transformer = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="median"))
    ])

    categorical_transformer = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore"))
    ])

    preprocessor = ColumnTransformer(
        transformers=[
            ("num", numeric_transformer, numeric_features),
            ("cat", categorical_transformer, categorical_features),
        ]
    )

    model = Pipeline(steps=[
        ("preprocessor", preprocessor),
        ("rf", RandomForestRegressor(
            n_estimators=n_estimators,
            max_depth=max_depth,
            random_state=random_state,
            n_jobs=-1
        ))
    ])

    model.fit(X_train, y_train)

    # D·ª± ƒëo√°n cho ƒë√°nh gi√°
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    metrics_dict = {
        "train_R2": metrics.r2_score(y_train, y_train_pred),
        "test_R2": metrics.r2_score(y_test, y_test_pred),
        "train_RMSE": np.sqrt(
            metrics.mean_squared_error(y_train, y_train_pred)
        ),
        "test_RMSE": np.sqrt(
            metrics.mean_squared_error(y_test, y_test_pred)
        ),
        "train_MAE": metrics.mean_absolute_error(y_train, y_train_pred),
        "test_MAE": metrics.mean_absolute_error(y_test, y_test_pred),
    }

    return model, X_train, X_test, y_train, y_test, metrics_dict


# Th·ª≠ load d·ªØ li·ªáu & train model m·∫∑c ƒë·ªãnh
try:
    df_raw, df_processed = load_data()
except Exception as e:
    df_raw, df_processed = None, None
    st.error(f"L·ªói khi ƒë·ªçc data_motobikes.xlsx: {e}")

if df_processed is not None:
    try:
        (model_default,
         X_train_default,
         X_test_default,
         y_train_default,
         y_test_default,
         metrics_default) = train_rf_model(df_processed)
    except Exception as e:
        model_default = None
        st.error(f"L·ªói khi train m√¥ h√¨nh m·∫∑c ƒë·ªãnh: {e}")
else:
    model_default = None

# =========================
# 5. MENU CH√çNH (PHI√äN B·∫¢N M·ªöI)
# =========================

menu_items = [
    "1. M·ª•c ti√™u d·ª± √°n",
    "2. ƒê√°nh gi√° & b√°o c√°o",
    "3. D·ª± ƒëo√°n gi√° xe m√°y c≈©",
    "4. Ph√°t hi·ªán b·∫•t th∆∞·ªùng - Ng∆∞·ªùi ƒëƒÉng tin",
    "5. Ph√°t hi·ªán b·∫•t th∆∞·ªùng ‚Äì Admin",
    "6. Nh√≥m th·ª±c hi·ªán"
]

choice = st.sidebar.radio("üìÇ Danh m·ª•c", menu_items)

# =========================
# 6. T·ª™NG M·ª§C MENU
# =========================

# ---------- 1. Business Problem ----------
if choice.startswith("1."):
    pastel_header("üìå", "M·ª•c ti√™u d·ª± √°n", "#fee2e2")

    st.markdown("""
    <style>
        .simple-text {
            font-family: Arial, sans-serif;
            font-size: 17px;
            line-height: 1.6;
            text-align: justify;
            margin-left: 18px;
            margin-right: 5px;
        }
    </style>
    """, unsafe_allow_html=True)

    st.markdown("""
    <div class="simple-text">

    **Ch·ª£ T·ªët** l√† n·ªÅn t·∫£ng mua b√°n tr·ª±c tuy·∫øn h√†ng ƒë·∫ßu t·∫°i Vi·ªát Nam. Ch·ª£ T·ªët cung c·∫•p ƒëa d·∫°ng c√°c d√≤ng s·∫£n ph·∫©m: nh√† c·ª≠a, xe √¥ t√¥, ƒë·ªì ƒëi·ªán t·ª≠ ƒë√£ qua s·ª≠ d·ª•ng, v·∫≠t nu√¥i, c√°c d·ªãch v·ª• gia ƒë√¨nh v√† tuy·ªÉn d·ª•ng.

    Th·ªã tr∆∞·ªùng xe m√°y c≈© tr√™n n·ªÅn t·∫£ng Ch·ª£ T·ªët r·∫•t phong ph√∫ v·ªÅ d√≤ng xe, nƒÉm s·∫£n xu·∫•t, t√¨nh tr·∫°ng s·ª≠ d·ª•ng, gi√° c·∫£,... khi·∫øn ng∆∞·ªùi mua kh√≥ khƒÉn trong vi·ªác x√°c ƒë·ªãnh gi√° h·ª£p l√Ω. M·ªôt v·∫•n ƒë·ªÅ c·∫ßn thi·∫øt n·ªØa ƒë∆∞·ª£c ƒë·∫∑t ra l√† ph√°t hi·ªán c√°c tin ƒëƒÉng c√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng, nh∆∞ gi√° qu√° r·∫ª ƒë·ªÉ thu h√∫t ng∆∞·ªùi xem ho·∫∑c gi√° qu√° cao g√¢y nhi·ªÖu th·ªã tr∆∞·ªùng.

    D·ª± √°n n√†y t·∫≠p trung v√†o ph√¢n kh√∫c xe m√°y c≈© v·ªõi hai m·ª•c ti√™u ch√≠nh:

    **1. D·ª± ƒëo√°n gi√° xe m√°y c≈©**  
    X√¢y d·ª±ng m√¥ h√¨nh h·ªçc m√°y c√≥ kh·∫£ nƒÉng d·ª± ƒëo√°n gi√° b√°n h·ª£p l√Ω c·ªßa xe m√°y d·ª±a tr√™n c√°c th√¥ng tin nh∆∞ h√£ng xe, d√≤ng xe, lo·∫°i xe, dung t√≠ch ƒë·ªông c∆°, xu·∫•t x·ª©, s·ªë km ƒë√£ ƒëi, tu·ªïi xe v√† t√¨nh tr·∫°ng s·ª≠ d·ª•ng. M·ª•c ti√™u l√† h·ªó tr·ª£ ng∆∞·ªùi mua v√† ng∆∞·ªùi b√°n ƒë∆∞a ra quy·∫øt ƒë·ªãnh ch√≠nh x√°c v√† nhanh ch√≥ng h∆°n.

    **2. Ph√°t hi·ªán c√°c tin ƒëƒÉng b·∫•t th∆∞·ªùng**  
    S·ª≠ d·ª•ng c√°c thu·∫≠t to√°n ph√°t hi·ªán b·∫•t th∆∞·ªùng (anomaly detection) ƒë·ªÉ nh·∫≠n di·ªán c√°c tin ƒëƒÉng c√≥ gi√° qu√° kh√°c bi·ªát so v·ªõi th·ªã tr∆∞·ªùng. ƒêi·ªÅu n√†y gi√∫p n·ªÅn t·∫£ng:

    - Gi·∫£m thi·ªÉu r·ªßi ro cho ng∆∞·ªùi mua (l·ª´a ƒë·∫£o, th√¥ng tin sai l·ªách).
    - N√¢ng cao ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu v√† ƒë·ªô tin c·∫≠y c·ªßa trang.
    - H·ªó tr·ª£ ƒë·ªôi ng≈© ki·ªÉm duy·ªát ph√°t hi·ªán s·ªõm c√°c tr∆∞·ªùng h·ª£p ƒë√°ng nghi.

    Th√¥ng qua vi·ªác k·∫øt h·ª£p m√¥ h√¨nh d·ª± ƒëo√°n gi√° v√† h·ªá th·ªëng c·∫£nh b√°o tin ƒëƒÉng b·∫•t th∆∞·ªùng, d·ª± √°n mang l·∫°i gi√° tr·ªã thi·∫øt th·ª±c cho c·∫£ ng∆∞·ªùi d√πng v√† n·ªÅn t·∫£ng nh·∫±m x√¢y d·ª±ng th·ªã tr∆∞·ªùng mua b√°n xe m√°y c≈© hi·ªáu qu·∫£ v√† ƒë√°ng tin c·∫≠y tr√™n chotot.com.

    </div>
    """, unsafe_allow_html=True)

# ---------- 2. Evaluation & Report ----------
elif choice.startswith("2."):
    pastel_header("üìä", "ƒê√°nh gi√° & b√°o c√°o", "#e0f2fe")

    # Hi·ªÉn th·ªã th√¥ng tin d·ªØ li·ªáu g·ªëc
    if df_raw is not None:
        st.markdown("##### üßæ D·ªØ li·ªáu g·ªëc")
        st.write(
            f"S·ªë h√†ng: {df_raw.shape[0]}, "
            f"s·ªë c·ªôt: {df_raw.shape[1]}"
        )
        st.dataframe(df_raw.head())
    else:
        st.warning(
            "Unable to read the file data_motobikes.xlsx ‚Äì "
            "please check the file path and file name."
        )

    # Ki·ªÉm tra d·ªØ li·ªáu & model m·∫∑c ƒë·ªãnh
    if (df_processed is None) or (model_default is None):
        st.error("Ch∆∞a c√≥ d·ªØ li·ªáu ho·∫∑c m√¥ h√¨nh. Vui l√≤ng ki·ªÉm tra l·∫°i.")
    else:
        # ===== K·∫øt qu·∫£ x√¢y d·ª±ng v√† l·ª±a ch·ªçn m√¥ h√¨nh (Select model.PNG) =====
        st.markdown("##### üìà K·∫øt qu·∫£ c·ªßa x√¢y d·ª±ng v√† l·ª±a ch·ªçn m√¥ h√¨nh")
        try:
            img_select = Image.open("Select model.PNG")
            st.image(
                img_select,
                use_container_width=True
            )
        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ load ·∫£nh 'Select model.PNG': {e}")
        st.markdown("**M√¥ h√¨nh ph√π h·ª£p nh·∫•t l√† Random Forest**")

        # ===== Visualization n·∫±m CU·ªêI C√ôNG =====
        st.markdown(
            "##### üìâ Tr·ª±c quan h√≥a k·∫øt qu·∫£ th·ª±c hi·ªán"
        )

        # H√¨nh 1: Price.PNG ‚Äì Comparison of Actual Price and Predicted Price
        try:
            img_price = Image.open("Price.PNG")
            st.image(
                img_price,
                use_container_width=True
            )
        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ load ·∫£nh 'Price.PNG': {e}")
        
        # H√¨nh 2: Anomaly_scores.PNG ‚Äì Distribution of Anomaly Scores
        try:
            img_scores = Image.open("Anomaly_scores.PNG")
            st.image(
                img_scores,
                use_container_width=True
            )
        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ load ·∫£nh 'Anomaly_scores.PNG': {e}")

# ---------- 3. Predicting Used Motorbike Prices ----------
elif choice.startswith("3."):
    pastel_header("üí∞", "D·ª± ƒëo√°n gi√° xe m√°y c≈©", "#fef3c7")

    if (df_processed is None) or (model_default is None):
        st.error("Ch∆∞a c√≥ d·ªØ li·ªáu ho·∫∑c m√¥ h√¨nh.")
    else:
        model_use = st.session_state.get("model_custom", model_default)
        df = df_processed.copy()

        # L·∫•y danh s√°ch option t·ª´ d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω
        def get_unique(col):
            return sorted(
                df[col].dropna().unique().tolist()
            ) if col in df.columns else []

        col1, col2 = st.columns(2)
        with col1:
            thuong_hieu = st.selectbox(
                "Th∆∞∆°ng hi·ªáu (thuong_hieu)", get_unique('thuong_hieu')
            )
            dong_xe = st.selectbox(
                "D√≤ng xe (dong_xe)", get_unique('dong_xe')
            )
            loai_xe = st.selectbox(
                "Lo·∫°i xe (loai_xe)",
                get_unique('loai_xe') if 'loai_xe' in df.columns else []
            )
            xuat_xu = st.selectbox(
                "Xu·∫•t x·ª© (xuat_xu)",
                get_unique('xuat_xu') if 'xuat_xu' in df.columns else []
            )
        with col2:
            dung_tich = st.selectbox(
                "Dung t√≠ch xe (dung_tich_xe)",
                get_unique('dung_tich_xe') if 'dung_tich_xe' in df.columns else []
            )
            tuoi_xe = st.slider("Tu·ªïi xe (nƒÉm)", 0, 30, 5)
            so_km_da_di = st.number_input(
                "S·ªë km ƒë√£ ƒëi (so_km_da_di)",
                min_value=0, value=30000, step=1000
            )

        # Chu·∫©n b·ªã 1 d√≤ng input theo c√°c c·ªôt X ƒë√£ d√πng khi train
        sample = {}
        X_cols = df.drop(columns=['gia']).columns.tolist()

        for c in X_cols:
            if c == 'thuong_hieu':
                sample[c] = thuong_hieu
            elif c == 'dong_xe':
                sample[c] = dong_xe
            elif c == 'loai_xe':
                sample[c] = loai_xe
            elif c == 'xuat_xu':
                sample[c] = xuat_xu
            elif c == 'dung_tich_xe':
                sample[c] = dung_tich
            elif c == 'tuoi_xe':
                sample[c] = tuoi_xe
            elif c == 'so_km_da_di':
                sample[c] = so_km_da_di
            else:
                # v·ªõi c√°c c·ªôt kh√°c, ƒë·ªÉ NaN cho pipeline x·ª≠ l√Ω
                sample[c] = np.nan

        input_df = pd.DataFrame([sample])

        st.markdown("##### üì• Th√¥ng tin xe")
        st.dataframe(input_df.drop(columns=['phan_khuc', 'khoang_gia_min', 'khoang_gia_max'],
                                   errors='ignore'))

        if st.button("Gi√° d·ª± ƒëo√°n"):
            try:
                y_pred = model_use.predict(input_df)[0]
                st.success(f"Gi√° d·ª± ƒëo√°n: {y_pred:.2f} tri·ªáu VND")
            except Exception as e:
                st.error(f"L·ªói khi g·ªçi model.predict: {e}")

# ---------- 4. PH√ÅT HI·ªÜN B·∫§T TH∆Ø·ªúNG - NG∆Ø·ªúI ƒêƒÇNG TIN ----------
elif choice.startswith("4."):
    pastel_header("üö®", "Ph√°t hi·ªán b·∫•t th∆∞·ªùng - Ng∆∞·ªùi ƒëƒÉng tin", "#ede9fe")

    if (df_processed is None) or (model_default is None):
        st.error("Ch∆∞a c√≥ d·ªØ li·ªáu ho·∫∑c m√¥ h√¨nh.")
    else:
        # ∆∞u ti√™n model_anom n·∫øu c√≥, sau ƒë√≥ model_custom, cu·ªëi c√πng model_default
        model_use = st.session_state.get(
            "model_anom",
            st.session_state.get("model_custom", model_default)
        )
        df = df_processed.copy()

        def get_unique(col):
            return sorted(
                df[col].dropna().unique().tolist()
            ) if col in df.columns else []

        col1, col2 = st.columns(2)
        with col1:
            thuong_hieu = st.selectbox(
                "Th∆∞∆°ng hi·ªáu (thuong_hieu)", get_unique('thuong_hieu')
            )
            dong_xe = st.selectbox(
                "D√≤ng xe (dong_xe)", get_unique('dong_xe')
            )
            loai_xe = st.selectbox(
                "Lo·∫°i xe (loai_xe)",
                get_unique('loai_xe') if 'loai_xe' in df.columns else []
            )
            xuat_xu = st.selectbox(
                "Xu·∫•t x·ª© (xuat_xu)",
                get_unique('xuat_xu') if 'xuat_xu' in df.columns else []
            )
        with col2:
            dung_tich = st.selectbox(
                "Dung t√≠ch xe (dung_tich_xe)",
                get_unique('dung_tich_xe') if 'dung_tich_xe' in df.columns else []
            )
            tuoi_xe = st.slider("Tu·ªïi xe (nƒÉm)", 0, 30, 5)
            so_km_da_di = st.number_input(
                "S·ªë km ƒë√£ ƒëi (so_km_da_di)",
                min_value=0, value=30000, step=1000
            )
            khoang_gia_min = st.number_input(
                "Kho·∫£ng gi√° min (khoang_gia_min) - tri·ªáu VND",
                min_value=0.0, value=0.0
            )
            khoang_gia_max = st.number_input(
                "Kho·∫£ng gi√° max (khoang_gia_max) - tri·ªáu VND",
                min_value=0.0, value=0.0
            )

        gia_thuc_te = st.number_input(
            "Gi√° xe (tri·ªáu VND)", min_value=0.0, value=30.0
        )

        # T·∫°o 1 d√≤ng data gi·ªëng c·∫•u tr√∫c df_processed
        sample = {}
        X_cols = df.drop(columns=['gia']).columns.tolist()

        for c in X_cols:
            if c == 'thuong_hieu':
                sample[c] = thuong_hieu
            elif c == 'dong_xe':
                sample[c] = dong_xe
            elif c == 'loai_xe':
                sample[c] = loai_xe
            elif c == 'xuat_xu':
                sample[c] = xuat_xu
            elif c == 'dung_tich_xe':
                sample[c] = dung_tich
            elif c == 'tuoi_xe':
                sample[c] = tuoi_xe
            elif c == 'so_km_da_di':
                sample[c] = so_km_da_di
            elif c == 'khoang_gia_min':
                sample[c] = khoang_gia_min if khoang_gia_min > 0 else np.nan
            elif c == 'khoang_gia_max':
                sample[c] = khoang_gia_max if khoang_gia_max > 0 else np.nan
            else:
                sample[c] = np.nan

        sample['gia'] = gia_thuc_te

        input_df = pd.DataFrame([sample])

        st.markdown("##### üÜï Th√¥ng tin xe")
        st.dataframe(input_df.drop(columns=['phan_khuc'], errors='ignore'))

        # d√πng threshold v√† df_anom t·ª´ session n·∫øu c√≥
        df_anom = st.session_state.get("df_anom", None)
        threshold = st.session_state.get("anom_threshold", 50)

        # Kh·ªüi t·∫°o bi·∫øn l∆∞u k·∫øt qu·∫£ ki·ªÉm tra
        if 'anom_check_result' not in st.session_state:
            st.session_state['anom_check_result'] = None

        col_btn1, col_btn2 = st.columns(2)
        with col_btn1:
            check_clicked = st.button("B∆∞·ªõc 1: Ki·ªÉm tra b·∫•t th∆∞·ªùng")
        with col_btn2:
            post_clicked = st.button("B∆∞·ªõc 2: ƒêƒÉng tin")

        # --- B∆∞·ªõc 1: Ki·ªÉm tra b·∫•t th∆∞·ªùng ---
        if check_clicked:
            try:
                # G·ªôp v√†o d·ªØ li·ªáu hi·ªán c√≥ ƒë·ªÉ t√≠nh score ·ªïn ƒë·ªãnh h∆°n
                df_all = pd.concat([df, input_df], ignore_index=True)

                # ƒê√ÅNH D·∫§U TIN M·ªöI
                df_all['is_new'] = 0
                df_all.loc[df_all.index[-1], 'is_new'] = 1  # d√≤ng cu·ªëi l√† tin m·ªõi

                df_all_anom, thres_used = detect_anomalies(
                    df_all, model_use, threshold=threshold, method="absolute"
                )

                # L·∫§Y ƒê√öNG TIN M·ªöI SAU KHI SORT THEO SCORE
                new_row = df_all_anom[df_all_anom['is_new'] == 1].iloc[0]
                score_new = new_row['score']
                is_anom_new = int(new_row['is_anomaly'])
                gia_pred_new = new_row['gia_predict']

                st.write(
                    f"**Gi√° th·ªã tr∆∞·ªùng (gi√° d·ª± ƒëo√°n):** {gia_pred_new:.2f} tri·ªáu VND"
                )
                st.write(
                    f"**Gi√° tin ƒëƒÉng (gi√° th·ª±c t·∫ø):** {gia_thuc_te:.2f} tri·ªáu VND"
                )
                st.write(
                    f"**Ch√™nh l·ªách (gi√° tin ƒëƒÉng - gi√° th·ªã tr∆∞·ªùng):** {new_row['resid']:.2f} tri·ªáu VND"
                )
                st.write(
                    f"**ƒêi·ªÉm b·∫•t th∆∞·ªùng (anomaly score):** {score_new:.2f} "
                    f"(ng∆∞·ª°ng: {thres_used:.2f})"
                )

                # L∆∞u k·∫øt qu·∫£ ki·ªÉm tra v√†o session_state
                st.session_state['anom_check_result'] = {
                    "is_anomaly": is_anom_new,
                    "input_df": input_df.to_dict(orient="list"),
                    "gia": float(new_row['gia']),
                    "gia_predict": float(new_row['gia_predict']),
                    "resid": float(new_row['resid']),
                    "score": float(new_row['score'])
                }

                if is_anom_new == 1:
                    st.error(
                        f"**Gi√° xe b·∫•t th∆∞·ªùng**.\n"
                        f"Ch√™nh l·ªách: {new_row['resid']:.2f} tri·ªáu VND so v·ªõi gi√° th·ªã tr∆∞·ªùng.\n\n"
                        f"N·∫øu b·∫°n v·∫´n mu·ªën ƒëƒÉng tin, h·ªá th·ªëng s·∫Ω chuy·ªÉn th√¥ng tin cho Admin qu·∫£n l√Ω ·ªü b∆∞·ªõc **ƒêƒÉng tin**."
                    )
                else:
                    st.success(
                        "**Gi√° xe ph√π h·ª£p**. B·∫°n c√≥ th·ªÉ b·∫•m **ƒêƒÉng tin** ƒë·ªÉ ho√†n t·∫•t."
                    )

            except Exception as e:
                st.error(f"L·ªói khi t√≠nh ƒëi·ªÉm b·∫•t th∆∞·ªùng: {e}")

        # --- B∆∞·ªõc 2: ƒêƒÉng tin ---
        if post_clicked:
            result = st.session_state.get('anom_check_result', None)
            if result is None:
                st.warning("Vui l√≤ng b·∫•m **Ki·ªÉm tra b·∫•t th∆∞·ªùng** tr∆∞·ªõc khi **ƒêƒÉng tin**.")
            else:
                if result["is_anomaly"] == 0:
                    # Gi√° ph√π h·ª£p -> ch·ªâ b√°o th√†nh c√¥ng, kh√¥ng l∆∞u file
                    st.success("ƒêƒÉng tin th√†nh c√¥ng!")
                else:
                    # Gi√° b·∫•t th∆∞·ªùng -> l∆∞u Excel v√† b√°o chuy·ªÉn cho Admin
                    try:
                        input_df_dict = result["input_df"]
                        input_df_post = pd.DataFrame(input_df_dict)

                        record = {}
                        record['thoi_gian_dang'] = dt.datetime.now()

                        # L∆∞u to√†n b·ªô th√¥ng tin tin ƒëƒÉng
                        for c in input_df_post.columns:
                            record[c] = input_df_post.iloc[0][c]

                        record['gia_thuc_te'] = result["gia"]
                        record['gia_du_doan'] = result["gia_predict"]
                        record['chenh_lech'] = result["resid"]
                        record['ly_do_bat_thuong'] = (
                            f"Gi√° tin ƒëƒÉng l·ªách {result['resid']:.2f} tri·ªáu VND "
                            f"so v·ªõi gi√° d·ª± ƒëo√°n"
                        )
                        record['anomaly_score'] = result["score"]

                        append_new_anomaly(record)

                        st.success(
                            "ƒêƒÉng tin th√†nh c√¥ng. **Chuy·ªÉn th√¥ng tin cho Admin qu·∫£n l√Ω.**"
                        )
                    except Exception as e:
                        st.error(f"L·ªói khi l∆∞u th√¥ng tin b·∫•t th∆∞·ªùng: {e}")

                # Sau khi ƒëƒÉng tin xong, xo√° k·∫øt qu·∫£ ki·ªÉm tra ƒë·ªÉ tr√°nh l∆∞u l·∫°i l·∫ßn n·ªØa
                st.session_state['anom_check_result'] = None

# ---------- 5. PH√ÅT HI·ªÜN B·∫§T TH∆Ø·ªúNG - ADMIN ----------
elif choice.startswith("5."):
    pastel_header("üö®", "Ph√°t hi·ªán b·∫•t th∆∞·ªùng ‚Äì Admin", "#ede9fe")

    if (df_processed is None) or (model_default is None):
        st.error("Ch∆∞a c√≥ d·ªØ li·ªáu ho·∫∑c m√¥ h√¨nh.")
    else:
        # ∆∞u ti√™n model_anom n·∫øu c√≥, sau ƒë√≥ model_custom, cu·ªëi c√πng model_default
        model_use = st.session_state.get(
            "model_anom",
            st.session_state.get("model_custom", model_default)
        )
        df = df_processed.copy()

        sub1, sub2 = st.tabs(
            ["Th·ªëng k√™ b·∫•t th∆∞·ªùng tr√™n d·ªØ li·ªáu g·ªëc",
             "Th·ªëng k√™ b·∫•t th∆∞·ªùng m·ªõi"]
        )

        # --- Ph·∫ßn 1: Th·ªëng k√™ b·∫•t th∆∞·ªùng tr√™n d·ªØ li·ªáu g·ªëc ---
        with sub1:
            st.markdown("##### üìä Th·ªëng k√™ b·∫•t th∆∞·ªùng tr√™n d·ªØ li·ªáu g·ªëc")
            try:
                # D√ôNG PH√ÇN V·ªä 95% -> T·ª∂ L·ªÜ M·∫™U B·∫§T TH∆Ø·ªúNG < 5%
                df_all_anom_goc, thres_goc = detect_anomalies(
                    df.copy(), model_use, threshold=95, method="percentile"
                )
                # L∆∞u l·∫°i cho ph·∫ßn kh√°c n·∫øu c·∫ßn
                st.session_state["df_anom"] = df_all_anom_goc
                st.session_state["anom_threshold"] = thres_goc

                df_anom_goc = df_all_anom_goc[df_all_anom_goc['is_anomaly'] == 1].copy()

                tong_bat_thuong = df_anom_goc.shape[0]
                tong_mau = df_all_anom_goc.shape[0]
                ty_le = 100.0 * tong_bat_thuong / tong_mau if tong_mau > 0 else 0.0

                st.write(
                    f"**T·ªïng s·ªë l∆∞·ª£ng m·∫´u b·∫•t th∆∞·ªùng:** {tong_bat_thuong} "
                    f"(~{ty_le:.2f}% c·ªßa to√†n b·ªô d·ªØ li·ªáu g·ªëc)"
                )

                if tong_bat_thuong > 0:
                    # Chu·∫©n b·ªã c√°c c·ªôt hi·ªÉn th·ªã theo y√™u c·∫ßu
                    df_display = df_anom_goc.copy()
                    df_display = df_display.rename(columns={
                        'gia': 'gia_thuc_te',
                        'gia_predict': 'gia_du_doan',
                        'score': 'anomaly_score'
                    })
                    df_display['chenh_lech'] = df_anom_goc['resid']
                    df_display['ly_do_bat_thuong'] = df_anom_goc['resid'].apply(
                        lambda x: f"Ch√™nh l·ªách {x:.2f} tri·ªáu VND so v·ªõi gi√° d·ª± ƒëo√°n"
                    )

                    # X√ìA C√ÅC C·ªòT K·ª∏ THU·∫¨T KH√îNG HI·ªÇN TH·ªä/EXPORT
                    drop_cols_admin = [
                        'resid', 'resid_z', 'vi_pham_minmax',
                        'ngoai_khoang_tin_cay', 'iso_score', 'is_anomaly'
                    ]
                    df_display = df_display.drop(columns=drop_cols_admin, errors='ignore')

                    # S·∫ÆP X·∫æP TH·ª® T·ª∞ C·ªòT
                    ordered_cols_admin = [
                        'thuong_hieu', 'dong_xe', 'so_km_da_di', 'loai_xe',
                        'dung_tich_xe', 'xuat_xu', 'tuoi_xe',
                        'khoang_gia_min', 'khoang_gia_max',
                        'gia_thuc_te', 'gia_du_doan', 'chenh_lech',
                        'ly_do_bat_thuong', 'anomaly_score'
                    ]
                    cols_exist_admin = [c for c in ordered_cols_admin if c in df_display.columns]
                    df_display = df_display[cols_exist_admin]

                    # Hi·ªÉn th·ªã 5 m·∫´u ƒë·∫ßu ti√™n
                    st.markdown("**5 m·∫´u b·∫•t th∆∞·ªùng ƒë·∫ßu ti√™n:**")
                    st.dataframe(df_display.head(5))

                    # N√∫t download Excel to√†n b·ªô m·∫´u b·∫•t th∆∞·ªùng
                    excel_buffer = io.BytesIO()
                    with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
                        df_display.to_excel(writer, index=False,
                                            sheet_name="Anomalies_goc")
                    excel_buffer.seek(0)

                    st.download_button(
                        label="‚¨áÔ∏è Xu·∫•t Excel to√†n b·ªô m·∫´u b·∫•t th∆∞·ªùng (d·ªØ li·ªáu g·ªëc)",
                        data=excel_buffer,
                        file_name="anomalies_goc.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                else:
                    st.info("Kh√¥ng ph√°t hi·ªán m·∫´u b·∫•t th∆∞·ªùng n√†o tr√™n d·ªØ li·ªáu g·ªëc.")
            except Exception as e:
                st.error(f"L·ªói khi th·ªëng k√™ b·∫•t th∆∞·ªùng tr√™n d·ªØ li·ªáu g·ªëc: {e}")

        # --- Ph·∫ßn 2: Th·ªëng k√™ b·∫•t th∆∞·ªùng m·ªõi ---
        with sub2:
            st.markdown("##### üÜï Th·ªëng k√™ c√°c tin ƒëƒÉng b·∫•t th∆∞·ªùng m·ªõi")

            df_new_anom = load_new_anomalies()

            if df_new_anom.empty:
                st.info("Ch∆∞a c√≥ tin ƒëƒÉng b·∫•t th∆∞·ªùng m·ªõi n√†o ƒë∆∞·ª£c l∆∞u.")
            else:
                # ƒê·∫£m b·∫£o c·ªôt th·ªùi gian
                if 'thoi_gian_dang' in df_new_anom.columns:
                    df_new_anom['thoi_gian_dang'] = pd.to_datetime(
                        df_new_anom['thoi_gian_dang'], errors='coerce'
                    )
                    # B·ªô l·ªçc theo th·ªùi gian
                    min_date = df_new_anom['thoi_gian_dang'].min().date()
                    max_date = df_new_anom['thoi_gian_dang'].max().date()

                    start_date, end_date = st.date_input(
                        "Ch·ªçn kho·∫£ng th·ªùi gian",
                        value=(min_date, max_date),
                        min_value=min_date,
                        max_value=max_date
                    )

                    if isinstance(start_date, dt.date) and isinstance(end_date, dt.date):
                        mask = (
                            (df_new_anom['thoi_gian_dang'].dt.date >= start_date) &
                            (df_new_anom['thoi_gian_dang'].dt.date <= end_date)
                        )
                        df_filtered = df_new_anom.loc[mask].copy()
                    else:
                        df_filtered = df_new_anom.copy()
                else:
                    df_filtered = df_new_anom.copy()

                # S·∫Øp x·∫øp gi·∫£m d·∫ßn theo th·ªùi gian
                if 'thoi_gian_dang' in df_filtered.columns:
                    df_filtered = df_filtered.sort_values(
                        by='thoi_gian_dang', ascending=False
                    )

                if 'gia_thuc_te' not in df_filtered.columns and 'gia' in df_filtered.columns:
                    df_filtered['gia_thuc_te'] = df_filtered['gia']
                if 'gia_du_doan' not in df_filtered.columns and 'gia_predict' in df_filtered.columns:
                    df_filtered['gia_du_doan'] = df_filtered['gia_predict']
                if 'anomaly_score' not in df_filtered.columns and 'score' in df_filtered.columns:
                    df_filtered['anomaly_score'] = df_filtered['score']
                if 'chenh_lech' not in df_filtered.columns and 'resid' in df_filtered.columns:
                    df_filtered['chenh_lech'] = df_filtered['resid']
                if 'ly_do_bat_thuong' not in df_filtered.columns and 'chenh_lech' in df_filtered.columns:
                    df_filtered['ly_do_bat_thuong'] = df_filtered['chenh_lech'].apply(
                        lambda x: f"Ch√™nh l·ªách {x:.2f} tri·ªáu VND so v·ªõi gi√° d·ª± ƒëo√°n"
                    )

                df_filtered = df_filtered.drop(columns=['gia'], errors='ignore')

                ordered_cols_new = [
                    'thoi_gian_dang', 'thuong_hieu', 'dong_xe', 'so_km_da_di',
                    'loai_xe', 'dung_tich_xe', 'xuat_xu', 'tuoi_xe',
                    'khoang_gia_min', 'khoang_gia_max',
                    'gia_thuc_te', 'gia_du_doan', 'chenh_lech',
                    'ly_do_bat_thuong', 'anomaly_score'
                ]
                cols_exist_new = [c for c in ordered_cols_new if c in df_filtered.columns]
                df_display_new = df_filtered[cols_exist_new]

                tong_tin_bat_thuong = df_display_new.shape[0]

                st.write(
                    f"**T·ªïng s·ªë l∆∞·ª£ng tin ƒëƒÉng b·∫•t th∆∞·ªùng:** {tong_tin_bat_thuong}"
                )

                if tong_tin_bat_thuong > 0:
                    st.markdown("**Danh s√°ch c√°c tin ƒëƒÉng b·∫•t th∆∞·ªùng:**")
                    st.dataframe(df_display_new)

                    # Xu·∫•t Excel theo b·ªô l·ªçc th·ªùi gian
                    excel_buffer_new = io.BytesIO()
                    with pd.ExcelWriter(excel_buffer_new, engine="openpyxl") as writer:
                        df_display_new.to_excel(writer, index=False,
                                                sheet_name="Anomalies_moi")
                    excel_buffer_new.seek(0)

                    st.download_button(
                        label="‚¨áÔ∏è Xu·∫•t Excel t·∫•t c·∫£ c√°c tin ƒëƒÉng b·∫•t th∆∞·ªùng",
                        data=excel_buffer_new,
                        file_name="anomalies_moi_filtered.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )

# ---------- 6. Th√¥ng tin nh√≥m ----------
elif choice.startswith("6."):
    pastel_header("üë•", "Th√†nh vi√™n", "#dcfce7")

    st.markdown("""

**Nguy·ªÖn Th·ªã Xu√¢n Mai**  
  - Email: nguyentxmai@gmail.com  
  - Ph·ª• tr√°ch: Ph√°t tri·ªÉn giao di·ªán GUI cho D·ª± √°n 1 ‚Äì D·ª± ƒëo√°n gi√° xe m√°y v√† ph√°t hi·ªán b·∫•t th∆∞·ªùng 

**Tr·∫ßn Th·ªã Y·∫øn Nhi**  
  - Email: yennhi1928@gmail.com  
  - Ph·ª• tr√°ch: Ph√°t tri·ªÉn giao di·ªán GUI cho D·ª± √°n 2 ‚Äì G·ª£i √Ω xe m√°y t∆∞∆°ng t·ª± v√† ph√¢n kh√∫c th·ªã tr∆∞·ªùng
""")